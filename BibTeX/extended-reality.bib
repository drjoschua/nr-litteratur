% Encoding: UTF-8

@Article{kuhlen1995virtual,
  author    = {Kuhlen, T. and Dohle, C.},
  journal   = {Computers in Biology and Medicine},
  title     = {Virtual reality for physically disabled people},
  year      = {1995},
  number    = {2},
  pages     = {205--211},
  volume    = {25},
  doi       = {https://doi.org/10.1016/0010-4825(94)00039-S},
  file      = {:extended-reality/kuhlen1995virtual.pdf:PDF},
  publisher = {Elsevier},
}

@Article{wilson1997virtual,
  author    = {Wilson, Paul N. and Foreman, Nigel and Stanton, Dana{\"e}},
  journal   = {Disability and rehabilitation},
  title     = {Virtual reality, disability and rehabilitation},
  year      = {1997},
  number    = {6},
  pages     = {213--220},
  volume    = {19},
  doi       = {https://doi.org/10.3109/09638289709166530},
  publisher = {Taylor \& Francis},
}

@Article{andrews2019extended,
  author    = {Andrews, Christopher and Southworth, Michael K. and Silva, Jennifer N.A. and Silva, Jonathan R.},
  journal   = {Current treatment options in cardiovascular medicine},
  title     = {Extended reality in medical practice},
  year      = {2019},
  number    = {4},
  pages     = {18},
  volume    = {21},
  doi       = {https://doi.org/10.1007/s11936-019-0722-7},
  file      = {:extended-reality/andrews2019extended.pdf:PDF},
  publisher = {Springer},
}

@Article{akcayir2017advantages,
  author    = {Ak{\c{c}}ay{\i}r, Murat and Ak{\c{c}}ay{\i}r, G{\"o}k{\c{c}}e},
  journal   = {Educational Research Review},
  title     = {Advantages and challenges associated with augmented reality for education: A systematic review of the literature},
  year      = {2017},
  pages     = {1--11},
  volume    = {20},
  doi       = {https://doi.org/10.1016/j.edurev.2016.11.002},
  file      = {:extended-reality/akcayir2017advantages.pdf:PDF},
  publisher = {Elsevier},
}

@Article{bacca2014augmented,
  author    = {Bacca, Jorge and Baldiris, Silvia and Fabregat, Ramon and Graf, Sabine and others},
  title     = {Augmented reality trends in education: a systematic review of research and applications},
  year      = {2014},
  file      = {:extended-reality/bacca2014augmented.pdf:PDF},
  publisher = {National Sun Yat-sen University},
}

@Article{koutromanos2015the,
  author    = {Koutromanos, George and Sofos, Alivisos and Avraamidou, Lucy},
  journal   = {Educational Media International},
  title     = {The use of augmented reality games in education: a review of the literature},
  year      = {2015},
  number    = {4},
  pages     = {253--271},
  volume    = {52},
  doi       = {https://www.tandfonline.com/doi/full/10.1080/09523987.2015.1125988},
  publisher = {Taylor \& Francis},
}

@Article{white2018a,
  author    = {White, Matthew P. and Yeo, Nicola L. and Vassiljev, Peeter and Lundstedt, Rikard and Wallerg{\aa}rd, Mattias and Albin, Maria and L{\~o}hmus, Mare},
  journal   = {Neuropsychiatric disease and treatment},
  title     = {A prescription for “nature”—The potential of using virtual nature in therapeutics.},
  year      = {2018},
  doi       = {http://dx.doi.org/10.2147/NDT.S179038},
  file      = {:extended-reality/white2018a.pdf:PDF},
  publisher = {Dove Medical Press Ltd.},
}

@Article{dascal2017virtual,
  author    = {Dascal, Julieta and Reid, Mark and IsHak, Waguih William and Spiegel, Brennan and Recacho, Jennifer and Rosen, Bradley and Danovitch, Itai},
  journal   = {Innovations in clinical neuroscience},
  title     = {Virtual reality and medical inpatients: A systematic review of randomized, controlled trials},
  year      = {2017},
  number    = {1-2},
  pages     = {14},
  volume    = {14},
  file      = {:extended-reality/dascal2017virtual.pdf:PDF},
  publisher = {Matrix Medical Communications},
}

@Article{jerdan2018head,
  author    = {Jerdan, Shaun W. and Grindle, Mark and van Woerden, Hugo C. and Boulos, Maged N. Kamel},
  journal   = {JMIR serious games},
  title     = {Head-mounted virtual reality and mental health: critical review of current research},
  year      = {2018},
  number    = {3},
  pages     = {e14},
  volume    = {6},
  doi       = {http://dx.doi.org/10.2196/games.9226},
  file      = {:extended-reality/jerdan2018head.pdf:PDF},
  publisher = {JMIR Publications Inc., Toronto, Canada},
}

@Article{litleskare2020enable,
  author    = {Litleskare, Sigbj{\o}rn and MacIntyre, Tadhg E and Calogiuri, Giovanna},
  journal   = {International Journal of Environmental Research and Public Health},
  title     = {Enable, reconnect and augment: a new era of virtual nature research and application},
  year      = {2020},
  number    = {5},
  pages     = {1738},
  volume    = {17},
  doi       = {https://doi.org/10.3390/ijerph17051738},
  file      = {:extended-reality/litleskare2020enable.pdf:PDF},
  publisher = {Multidisciplinary Digital Publishing Institute},
}

@Article{omaki2017systematic,
  author    = {Omaki, Elise and Rizzutti, Nicholas and Shields, Wendy and Zhu, Jeffrey and McDonald, Eileen and Stevens, Martha W. and Gielen, Andrea},
  journal   = {Injury prevention},
  title     = {A systematic review of technology-based interventions for unintentional injury prevention education and behaviour change},
  year      = {2017},
  number    = {2},
  pages     = {138--146},
  volume    = {23},
  doi       = {http://dx.doi.org/10.1136/injuryprev-2015-041740},
  file      = {:extended-reality/omaki2016a.pdf:PDF},
  publisher = {BMJ Publishing Group Ltd},
}

@Article{fox2009virtual,
  author    = {Fox, Jesse and Bailenson, Jeremy N.},
  journal   = {Media Psychology},
  title     = {Virtual self-modeling: The effects of vicarious reinforcement and identification on exercise behaviors},
  year      = {2009},
  number    = {1},
  pages     = {1--25},
  volume    = {12},
  doi       = {https://doi.org/10.1080/15213260802669474},
  file      = {:extended-reality/fox2009virtual.pdf:PDF},
  publisher = {Taylor \& Francis},
}

@Article{nosek2016an,
  author    = {Nosek, Margaret A. and Robinson-Whelen, Susan and Hughes, Rosemary B. and Nosek, Thomas M.},
  journal   = {Rehabilitation psychology},
  title     = {An Internet-based virtual reality intervention for enhancing self-esteem in women with disabilities: Results of a feasibility study},
  year      = {2016},
  number    = {4},
  pages     = {358},
  volume    = {61},
  doi       = {https://doi.org/10.1037/rep0000107},
  file      = {:extended-reality/nosek2016an.pdf:PDF},
  publisher = {American Psychological Association},
}

@InCollection{newbutt2017the,
  author    = {Newbutt, Nigel and Sung, Connie and Kuo, Hung Jen and Leahy, Michael J.},
  booktitle = {Recent Advances in Technologies for Inclusive Well-Being},
  publisher = {Springer},
  title     = {The acceptance, challenges, and future applications of wearable technology and virtual reality to support people with autism spectrum disorders},
  year      = {2017},
  pages     = {221--241},
  doi       = {https://doi.org/10.1007/978-3-319-49879-9},
  file      = {:extended-reality/newbutt2017the.pdf:PDF},
}

@Article{cai2013design,
  author    = {Cai, Yiyu and Chia, Noel K.H. and Thalmann, Daniel and Kee, Norman K.N. and Zheng, Jianmin and Thalmann, Nadia M.},
  journal   = {IEEE transactions on neural systems and rehabilitation engineering},
  title     = {Design and development of a virtual dolphinarium for children with autism},
  year      = {2013},
  number    = {2},
  pages     = {208--217},
  volume    = {21},
  doi       = {https://doi.org/10.1109/tnsre.2013.2240700},
  publisher = {IEEE},
}

@Article{alex2020virtual,
  author    = {Alex, Marylyn and W{\"u}nsche, Burkhard C. and Lottridge, Danielle},
  journal   = {International Journal of Human-Computer Studies},
  title     = {Virtual Reality Art-Making for Stroke Rehabilitation: Field Study and Technology Probe},
  year      = {2020},
  pages     = {102481},
  doi       = {https://doi.org/10.1016/j.ijhcs.2020.102481},
  file      = {:extended-reality/alex2020virtual.pdf:PDF},
  publisher = {Elsevier},
}

@InCollection{badia2016virtual,
  author    = {i Badia, Sergi Berm{\'u}dez and Fluet, Gerard G. and Llorens, Roberto and Deutsch, Judith E.},
  booktitle = {Neurorehabilitation technology},
  publisher = {Springer},
  title     = {Virtual reality for sensorimotor rehabilitation post stroke: Design principles and evidence},
  year      = {2016},
  pages     = {573--603},
  doi       = {https://doi.org/10.1016/j.ijhcs.2020.102481},
  file      = {:extended-reality/badia2016virtual.pdf:PDF},
}

@InProceedings{mott2019accessible,
  author       = {Mott, Martez and Cutrell, Edward and Franco, Mar Gonzalez and Holz, Christian and Ofek, Eyal and Stoakley, Richard and Morris, Meredith Ringel},
  booktitle    = {2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)},
  title        = {Accessible by design: An opportunity for virtual reality},
  year         = {2019},
  organization = {IEEE},
  pages        = {451--454},
  doi          = {https://doi.org/10.1109/ISMAR-Adjunct.2019.00122},
  file         = {:extended-reality/mott2019accessible.pdf:PDF},
}

@InProceedings{zhao2019seeingvr,
  author    = {Zhao, Yuhang and Cutrell, Edward and Holz, Christian and Morris, Meredith Ringel and Ofek, Eyal and Wilson, Andrew D.},
  booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
  title     = {SeeingVR: A set of tools to make virtual reality more accessible to people with low vision},
  year      = {2019},
  pages     = {1--14},
  doi       = {https://doi.org/10.1145/3290605.3300341},
  file      = {:extended-reality/zhao2019seeingvr.pdf:PDF},
}

@Article{paradiso2009guest,
  author    = {Paradiso, Joseph A and Landay, James A},
  journal   = {IEEE Pervasive Computing},
  title     = {Guest editors' introduction: Cross-reality environments},
  year      = {2009},
  number    = {3},
  pages     = {14--15},
  volume    = {8},
  doi       = {https://doi.org/10.1109/MPRV.2009.47},
  file      = {:extended-reality/paradiso2009cross.pdf:PDF},
  publisher = {IEEE},
}

@InProceedings{zhao2018enabling,
  author    = {Zhao, Yuhang and Bennett, Cynthia L. and Benko, Hrvoje and Cutrell, Edward and Holz, Christian and Morris, Meredith Ringel and Sinclair, Mike},
  booktitle = {Proceedings of the 2018 {CHI} {Conference} on {Human} {Factors} in {Computing} {Systems}},
  title     = {Enabling {People} with {Visual} {Impairments} to {Navigate} {Virtual} {Reality} with a {Haptic} and {Auditory} {Cane} {Simulation}},
  year      = {2018},
  address   = {Montreal QC, Canada},
  month     = apr,
  pages     = {1--14},
  publisher = {Association for Computing Machinery},
  series    = {{CHI} '18},
  abstract  = {Traditional virtual reality (VR) mainly focuses on visual feedback, which is not accessible for people with visual impairments. We created Canetroller, a haptic cane controller that simulates white cane interactions, enabling people with visual impairments to navigate a virtual environment by transferring their cane skills into the virtual world. Canetroller provides three types of feedback: (1) physical resistance generated by a wearable programmable brake mechanism that physically impedes the controller when the virtual cane comes in contact with a virtual object; (2) vibrotactile feedback that simulates the vibrations when a cane hits an object or touches and drags across various surfaces; and (3) spatial 3D auditory feedback simulating the sound of real-world cane interactions. We designed indoor and outdoor VR scenes to evaluate the effectiveness of our controller. Our study showed that Canetroller was a promising tool that enabled visually impaired participants to navigate different virtual spaces. We discuss potential applications supported by Canetroller ranging from entertainment to mobility training.},
  doi       = {10.1145/3173574.3173690},
  file      = {:extended-reality/zhao2018enabling.pdf:PDF},
  isbn      = {9781450356206},
  keywords  = {mobility, haptic feedback, auditory feedback, blindness, white cane, visual impairments, virtual reality},
  url       = {https://doi.org/10.1145/3173574.3173690},
  urldate   = {2020-08-26},
}

@InProceedings{gonzalezfranco2014empowering,
  author    = {Gonzalez-Franco, Mar and Gilroy, Scott and Moore, John O.},
  booktitle = {2014 36th {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society}},
  title     = {Empowering patients to perform physical therapy at home},
  year      = {2014},
  month     = aug,
  note      = {ISSN: 1558-4615},
  pages     = {6308--6311},
  abstract  = {In this paper we address the problem of patient adherence to physical therapy using a sensor-enabled virtual reality gaming interface that motivates users to complete their exercises while collecting quantitative data. The system also allows the therapist to monitor and interact with patients remotely providing reinforcing feedback and support with the CollaboRhythm care delivery platform. The data collected with this system enables the therapist and the patient to make informed decisions about patient treatment and exercise regimens based on the patient progress. The system is capable of supporting a wide array of rehabilitation scenarios with remote collaboration. A knee replacement scenario was tested with an experimental protocol involving 16 healthy participants. The results show both quantitatively and qualitatively that patients can learn intuitively to perform their physical therapy exercises on a remote environment without further human intervention.},
  doi       = {10.1109/EMBC.2014.6945071},
  file      = {:extended-reality/gonzalezfranco2014empowering.pdf:PDF},
  issn      = {1558-4615},
  keywords  = {medical computing, patient rehabilitation, serious games (computing), telemedicine, virtual reality, home based physical therapy, sensor enabled virtual reality gaming interface, patient rehabilitative exercises, remote patient monitoring, remote patient-therapist interaction, remote collaboration, knee replacement scenario, Medical treatment, Games, Knee, Real-time systems, Protocols, Avatars, Pain, Adult, Computer Simulation, Exercise Movement Techniques, Exercise Therapy, Feedback, Female, Humans, Male, Monitoring, Physiologic, Patient Compliance, Power (Psychology), Software, Young Adult},
}

@Article{falconer2014embodying,
  author     = {Falconer, Caroline J. and Slater, Mel and Rovira, Aitor and King, John A. and Gilbert, Paul and Antley, Angus and Brewin, Chris R.},
  journal    = {PLOS ONE},
  title      = {Embodying {Compassion}: {A} {Virtual} {Reality} {Paradigm} for {Overcoming} {Excessive} {Self}-{Criticism}},
  year       = {2014},
  issn       = {1932-6203},
  month      = nov,
  number     = {11},
  pages      = {e111933},
  volume     = {9},
  abstract   = {Virtual reality has been successfully used to study and treat psychological disorders such as phobias and posttraumatic stress disorder but has rarely been applied to clinically-relevant emotions other than fear and anxiety. Self-criticism is a ubiquitous feature of psychopathology and can be treated by increasing levels of self-compassion. We exploited the known effects of identification with a virtual body to arrange for healthy female volunteers high in self-criticism to experience self-compassion from an embodied first-person perspective within immersive virtual reality. Whereas observation and practice of compassionate responses reduced self-criticism, the additional experience of embodiment also increased self-compassion and feelings of being safe. The results suggest potential new uses for immersive virtual reality in a range of clinical conditions.},
  doi        = {10.1371/journal.pone.0111933},
  file       = {:extended-reality/falconer2014embodying.PDF:PDF},
  keywords   = {Virtual reality, Emotions, Relaxation (psychology), Eyes, Mental health therapies, Rubber, Fear, Mental health and psychiatry},
  language   = {en},
  publisher  = {Public Library of Science},
  shorttitle = {Embodying {Compassion}},
  url        = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0111933},
  urldate    = {CURRENT\_TIMESTAMP},
}

@Article{osimo2015conversations,
  author    = {Osimo, Sofia Adelaide and Pizarro, Rodrigo and Spanlang, Bernhard and Slater, Mel},
  journal   = {Scientific Reports},
  title     = {Conversations between self and self as {Sigmund} {Freud}—{A} virtual body ownership paradigm for self counselling},
  year      = {2015},
  issn      = {2045-2322},
  month     = sep,
  number    = {1},
  pages     = {13899},
  volume    = {5},
  abstract  = {When people see a life-sized virtual body (VB) from first person perspective in virtual reality they are likely to have the perceptual illusion that it is their body. Additionally such virtual embodiment can lead to changes in perception, implicit attitudes and behaviour based on attributes of the VB. To date the changes that have been studied are as a result of being embodied in a body representative of particular social groups (e.g., children and other race). In our experiment participants alternately switched between a VB closely resembling themselves where they described a personal problem and a VB representing Dr Sigmund Freud, from which they offered themselves counselling. Here we show that when the counsellor resembles Freud participants improve their mood, compared to the counsellor being a self-representation. The improvement was greater when the Freud VB moved synchronously with the participant, compared to asynchronously. Synchronous VB movement was associated with a much stronger illusion of ownership over the Freud body. This suggests that this form of embodied perspective taking can lead to sufficient detachment from habitual ways of thinking about personal problems, so as to improve the outcome and demonstrates the power of virtual body ownership to effect cognitive changes.},
  copyright = {2015 The Author(s)},
  doi       = {10.1038/srep13899},
  file      = {:extended-reality/osimo2015conversations.pdf:PDF},
  language  = {en},
  publisher = {Nature Publishing Group},
  url       = {https://www.nature.com/articles/srep13899},
  urldate   = {CURRENT\_TIMESTAMP},
}

@Article{you2005virtual,
  author     = {You, Sung and Jang, Sung and Kim, Yun-Hee and Hallett, Mark and Ahn, Sang and Kwon, Yong-Hyun and Kim, Joong and Lee, Mi},
  journal    = {Stroke},
  title      = {Virtual {Reality}–{Induced} {Cortical} {Reorganization} and {Associated} {Locomotor} {Recovery} in {Chronic} {Stroke}: {An} {Experimenter}-{Blind} {Randomized} {Study}},
  year       = {2005},
  issn       = {0039-2499},
  month      = jun,
  number     = {6},
  pages      = {1166--1171},
  volume     = {36},
  abstract   = {Background and Purpose—Virtual reality (VR) is a new promising computer-assisted technology to promote motor recovery in stroke patients. VR-induced neuroplasticity supporting locomotor recovery is not known. We investigated the effects of VR intervention on cortical reorganization and associated lo},
  doi        = {10.1161/01.STR.0000162715.43417.91},
  file       = {:extended-reality/you2005virtual.pdf:PDF},
  language   = {ENGLISH},
  pmid       = {15890990},
  shorttitle = {Virtual {Reality}–{Induced} {Cortical} {Reorganization} and {Associated} {Locomotor} {Recovery} in {Chronic} {Stroke}},
  url        = {insights.ovid.com},
  urldate    = {CURRENT\_TIMESTAMP},
}

@InProceedings{gonzalezmora2006seeing,
  author     = {Gonzalez-Mora, J.L. and Rodriguez-Hernandez, A. and Burunat, E. and Martin, F. and Castellano, M.A.},
  booktitle  = {2006 2nd {International} {Conference} on {Information} {Communication} {Technologies}},
  title      = {Seeing the world by hearing: {Virtual} {Acoustic} {Space} ({VAS}) a new space perception system for blind people.},
  year       = {2006},
  month      = apr,
  pages      = {837--842},
  volume     = {1},
  abstract   = {Virtual Acoustic Space (VAS) is a research and development project on the perception of space using only sound. A portable electronic prototype that allows blind people to receive spatial information of their surroundings has been developed. This information is perceived via an audible image using Head Related Transfer Function (HRTFs) processed sounds. The main goal is to create for the user the illusion that the surrounding objects are covered by small sound continuously emitting sources in a particular and sustained way. Therefore, a virtual acoustic world is generated, where a physical object emit sounds from all the coordinates of its surface. Our results validate the hypothesis that, it is possible to generate an experience of global and sustained presence of different objects inside the perception field from these stimuli, with the same shape, dimensions and location as the real environment. Our objectives are now focused on: a better delimitation of the observed capabilities, the study of the developed prototype in everyday life conditions, on exploring how blind people learn to use new strategies to improve their perception of the environment and the exploration of the possible cortical brain areas involved in this process, using functional imaging techniques},
  doi        = {10.1109/ICTTA.2006.1684482},
  file       = {:extended-reality/gonzalezmora2006seeing.pdf:PDF},
  keywords   = {acoustic signal processing, handicapped aids, virtual reality, Virtual Acoustic Space, space perception system, blind people, portable electronic prototype, audible image, head related transfer function processed sounds, virtual acoustic world, Auditory system, Brain modeling, Prototypes, Shape, Virtual prototyping, Physiology, Research and development, Head, Transfer functions, Acoustic emission},
  shorttitle = {Seeing the world by hearing},
}

@Article{picinali2014exploration,
  author   = {Picinali, Lorenzo and Afonso, Amandine and Denis, Michel and Katz, Brian F. G.},
  journal  = {International Journal of Human-Computer Studies},
  title    = {Exploration of architectural spaces by blind people using auditory virtual reality for the construction of spatial knowledge},
  year     = {2014},
  issn     = {1071-5819},
  month    = apr,
  number   = {4},
  pages    = {393--407},
  volume   = {72},
  abstract = {Navigation within a closed environment requires analysis of a variety of acoustic cues, a task that is well developed in many visually impaired individuals, and for which sighted individuals rely almost entirely on visual information. For blind people, the act of creating cognitive maps for spaces, such as home or office buildings, can be a long process, for which the individual may repeat various paths numerous times. While this action is typically performed by the individual on-site, it is of some interest to investigate at which point this task can be performed off-site, at the individual's discretion. In short, is it possible for an individual to learn an architectural environment without being physically present? If so, such a system could prove beneficial for navigation preparation in new and unknown environments. The main goal of the present research can therefore be summarized as investigating the possibilities of assisting blind individuals in learning a spatial environment configuration through the listening of audio events and their interactions with these events within a virtual reality experience. A comparison of two types of learning through auditory exploration has been performed: in situ real displacement and active navigation in a virtual architecture. The virtual navigation rendered only acoustic information. Results for two groups of five participants showed that interactive exploration of virtual acoustic room simulations can provide sufficient information for the construction of coherent spatial mental maps, although some variations were found between the two environments tested in the experiments. Furthermore, the mental representation of the virtually navigated environments preserved topological and metric properties, as was found through actual navigation.},
  doi      = {10.1016/j.ijhcs.2013.12.008},
  file     = {:extended-reality/picinali2014exploration.pdf:PDF},
  keywords = {Blind people, Visually impaired, Spatial hearing, Binaural, Virtual reality, Spatial cognition, Room acoustic simulation},
  language = {en},
  url      = {http://www.sciencedirect.com/science/article/pii/S1071581913002036},
  urldate  = {2020-08-27TZ},
}

@Article{maidenbaum2013increasing,
  author     = {Maidenbaum, Shachar and Levy-Tzedek, Shelly and Chebat, Daniel-Robert and Amedi, Amir},
  journal    = {PLOS ONE},
  title      = {Increasing {Accessibility} to the {Blind} of {Virtual} {Environments}, {Using} a {Virtual} {Mobility} {Aid} {Based} {On} the {EyeCane}: {Feasibility} {Study}},
  year       = {2013},
  issn       = {1932-6203},
  month      = aug,
  number     = {8},
  pages      = {e72555},
  volume     = {8},
  abstract   = {Virtual worlds and environments are becoming an increasingly central part of our lives, yet they are still far from accessible to the blind. This is especially unfortunate as such environments hold great potential for them for uses such as social interaction, online education and especially for use with familiarizing the visually impaired user with a real environment virtually from the comfort and safety of his own home before visiting it in the real world. We have implemented a simple algorithm to improve this situation using single-point depth information, enabling the blind to use a virtual cane, modeled on the “EyeCane” electronic travel aid, within any virtual environment with minimal pre-processing. Use of the Virtual-EyeCane, enables this experience to potentially be later used in real world environments with identical stimuli to those from the virtual environment. We show the fast-learned practical use of this algorithm for navigation in simple environments.},
  doi        = {10.1371/journal.pone.0072555},
  file       = {:extended-reality/maidenbaum2013increasing.pdf:PDF},
  keywords   = {Blindness, Human learning, Visual impairments, Sensory perception, Algorithms, Vision, Computer object recognition, Hearing},
  language   = {en},
  publisher  = {Public Library of Science},
  shorttitle = {Increasing {Accessibility} to the {Blind} of {Virtual} {Environments}, {Using} a {Virtual} {Mobility} {Aid} {Based} {On} the {EyeCane}},
  url        = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0072555},
  urldate    = {CURRENT\_TIMESTAMP},
}

@InProceedings{colwell1998haptic,
  author    = {Colwell, Chetz and Petrie, Helen and Kornbrot, Diana and Hardwick, Andrew and Furner, Stephen},
  booktitle = {Proceedings of the third international {ACM} conference on {Assistive} technologies},
  title     = {Haptic virtual reality for blind computer users},
  year      = {1998},
  address   = {Marina del Rey, California, USA},
  month     = jan,
  pages     = {92--99},
  publisher = {Association for Computing Machinery},
  series    = {Assets '98},
  abstract  = {This paper describes a series of studies involving a haptic device which can display virtual textures and 3-D objects. The device has potential for simulating real world objects and assisting in the navigation of virtual environments. Three experiments investigated: (a) whether previous results from experiments using real textures could be replicated using virtual textures; (b) whether participants perceived virtual objects to have the intended size and angle; and (c) whether simulated real objects could be recognised. In all the experiments differences in perception by blind and sighted people were also explored. The results have implications for the future design of VEs in that it cannot be assumed that virtual textures and objects will feel to the user as the designer intends. However, they do show that a haptic interface has considerable potential for blind computer users.},
  doi       = {10.1145/274497.274515},
  file      = {:extended-reality/colwell1998haptic.pdf:PDF},
  isbn      = {9781581130201},
  keywords  = {blind users, World Wide Web, perception of virtual textures and objects, haptic device, virtual environments},
  url       = {https://doi.org/10.1145/274497.274515},
  urldate   = {2020-08-27},
}

@InProceedings{kunz2018virtual,
  author    = {Kunz, Andreas and Miesenberger, Klaus and Zeng, Limin and Weber, Gerhard},
  booktitle = {Computers {Helping} {People} with {Special} {Needs}},
  title     = {Virtual {Navigation} {Environment} for {Blind} and {Low} {Vision} {People}},
  year      = {2018},
  address   = {Cham},
  editor    = {Miesenberger, Klaus and Kouroupetroglou, Georgios},
  pages     = {114--122},
  publisher = {Springer International Publishing},
  series    = {Lecture {Notes} in {Computer} {Science}},
  abstract  = {For comprehensively participating in society, independent and safe mobility is an important skill for many daily activities. Spatial cognition is one of the most important human capabilities and addresses the acquisition, processing and utilization of knowledge about the spatial layout of environments. Humans predominantly use the visual sense for this and for blind and low vision people, the lack of spatial perception reduces their quality of life and their ability of independent living. In particular the spatial navigation in unknown environments imposes challenges, since there is no possibility to train navigation tasks in advance. Today, blind and visually impaired people still rely on traditional navigation aids such as a cane for micro-navigation, which - however - does not help for developing orientation at larger scale or for planning of routes. To overcome this problem, this paper introduces the concept of a virtual environment that allows experiencing unknown locations by real walking while still staying in a sage controlled environment. Since this virtual environment can be controlled in its complexity, it can be adjusted from an abstract training scenario to a real-life situation such as train stations or airports.},
  doi       = {10.1007/978-3-319-94274-2_17},
  file      = {:extended-reality/kunz2018virtual.pdf:PDF},
  isbn      = {9783319942742},
  keywords  = {Virtual reality , Real walking , Training environment },
  language  = {en},
}

@InProceedings{lecuyer2003homere,
  author     = {Lecuyer, A. and Mobuchon, P. and Megard, C. and Perret, J. and Andriot, C. and Colinot, J.-P.},
  booktitle  = {{IEEE} {Virtual} {Reality}, 2003. {Proceedings}.},
  title      = {{HOMERE}: a multimodal system for visually impaired people to explore virtual environments},
  year       = {2003},
  month      = mar,
  note       = {ISSN: 1087-8270},
  pages      = {251--258},
  abstract   = {The paper describes the HOMERE system: a multimodal system dedicated to visually impaired people to explore and navigate inside virtual environments. The system addresses three main applications: preparation for the visit of an existing site, training for the use of a blind cane, and ludic exploration of virtual worlds. The HOMERE system provides the user with different sensations when navigating inside a virtual world: a force feedback corresponding to the manipulation of a virtual blind cane, a thermal feedback corresponding to the simulation of a virtual sun, and an auditory feedback in spatialized conditions corresponding to the ambient atmosphere and specific events in the simulation. A visual feedback of the scene is also provided to enable sighted people to follow the navigation of the main user. HOMERE has been tested by several visually impaired people who were all confident about the potential of this prototype.},
  doi        = {10.1109/VR.2003.1191147},
  file       = {:extended-reality/lecuyer2003homere.pdf:PDF},
  issn       = {1087-8270},
  keywords   = {handicapped aids, virtual reality, force feedback, digital simulation, HOMERE, multimodal system, visually impaired people, virtual environments, ludic exploration, virtual worlds, force feedback, virtual blind cane manipulation, thermal feedback, virtual sun simulation, auditory feedback, ambient atmosphere, visual feedback, Virtual environment, Navigation, Force feedback, Atmospheric modeling, Discrete event simulation, Thermal force, Sun, Atmosphere, Layout, Testing},
  shorttitle = {{HOMERE}},
}

@Misc{osullivan2015aprototype,
  author    = {O'Sullivan, Liam and Picinali, Lorenzo and Gerino, Andrea and Cawthorne, Douglas},
  month     = oct,
  title     = {A {Prototype} {Audio}-{Tactile} {Map} {System} with an {Advanced} {Auditory} {Display}},
  year      = {2015},
  abstract  = {Tactile surfaces can display information in a variety of applications for all users, but can be of particular benefit to blind and visually impaired individuals. One example is the use of paper-based tactile maps as navigational aids for interior and exterior spaces; visually impaired individuals ma...},
  copyright = {Access limited to members},
  doi       = {10.4018/IJMHCI.2015100104},
  file      = {:extended-reality/osullivan2015aprototype.pdf:PDF},
  issn      = {1942-390X},
  journal   = {International Journal of Mobile Human Computer Interaction (IJMHCI)},
  language  = {en},
  number    = {4},
  pages     = {53--75},
  publisher = {IGI Global},
  url       = {www.igi-global.com/article/a-prototype-audio-tactile-map-system-with-an-advanced-auditory-display/132651},
  urldate   = {CURRENT\_TIMESTAMP},
  volume    = {7},
}

@Article{poyade2019isensevr,
  author     = {Poyade, Matthieu and Morris, Glyn and Taylor, Ian C. and Portela, Victor},
  journal    = {Journal of Enabling Technologies},
  title      = {{iSenseVR}: bringing {VR} exposure therapy outside the laboratory},
  year       = {2019},
  issn       = {2398-6263},
  month      = jan,
  number     = {2},
  pages      = {123--134},
  volume     = {13},
  abstract   = {Purpose The purpose of this paper is to present the preliminary outcomes of a research which takes gradual exposure in virtual reality (VR) outside the laboratory to empower people with “hidden disabilities” breaking down their barriers towards independent living. It explores the use of VR through smartphones to practically apply gradual exposure to environment stressors that are typically found in busy spaces from one’s own safe environment. Design/methodology/approach Aberdeen International Airport has kindly accepted to take part to this research as a case study. Following a participatory design and usability testing, a semi-controlled seven-day study was conducted among seven individuals with hidden disabilities to assess user acceptance. Findings Results showed undeniable participants’ engagement and enthusiasm for the proposed approach, although further research is needed to increase the presence and improve the overall user experience. Research limitations/implications The proposed research has been conducted on small cohort of participants outside of a clinical setting. Further engagement with individuals with hidden disabilities is required in order to determine the effectiveness of the proposed approach. Originality/value This research presents a methodological and technological framework which contributes effectively to the practicality of VR exposure therapy outside of the laboratory setting, from one’s own safe place.},
  doi        = {10.1108/JET-12-2018-0063},
  file       = {:extended-reality/poyade2019isensevr.pdf:PDF},
  keywords   = {Anxiety, Smartphones, Virtual reality, Exposure therapy, Hidden disabilities, Neurodevelopmental disorders},
  publisher  = {Emerald Publishing Limited},
  shorttitle = {{iSenseVR}},
  url        = {https://doi.org/10.1108/JET-12-2018-0063},
  urldate    = {2020-08-27TZ},
}

@InProceedings{poyade2017using,
  author    = {Poyade, Matthieu and Morris, Glyn and Taylor, Ian and Portela, Victor},
  booktitle = {Proceedings of the 19th {ACM} {International} {Conference} on {Multimodal} {Interaction}},
  title     = {Using mobile virtual reality to empower people with hidden disabilities to overcome their barriers},
  year      = {2017},
  address   = {Glasgow, UK},
  month     = nov,
  pages     = {504--505},
  publisher = {Association for Computing Machinery},
  series    = {{ICMI} '17},
  abstract  = {This paper presents a proof of concept for an immersive and interactive mobile application which aims to help people with hidden disabilities to develop tolerance to the environmental stressors that are typically found in crowded public spaces, and more particularly in airports. The application initially proposes the user to rehearse a series of sensory attenuated experiences within digitally reconstructed environments of the Aberdeen International Airport. Throughout rehearsals, environmental stressors are gradually increased making the environments more sensory challenging for the user. Usability and pilot testing provided encouraging outcomes ahead of future developments.},
  doi       = {10.1145/3136755.3143025},
  file      = {:extended-reality/poyade2017using.pdf:PDF},
  isbn      = {9781450355438},
  keywords  = {Sensory perception, Autism, Accessibility, Virtual Reality Exposure Therapy, Hidden Disabilities, Anxiety, Virtual Reality, Airport},
  url       = {https://doi.org/10.1145/3136755.3143025},
  urldate   = {2020-08-27},
}

@Comment{jabref-meta: databaseType:bibtex;}
